# Minigraph performs an approximate mapping of assemblies to a backbone genome to construct the pangenome. 
# In contrast, Cactus and pggb apply reference-free base level alignment to build pangenome graphs.
# PGGB first performs reference-free multiple sequence alignment of all input sequences and then infers a graph using these alignments
# whereas minigraph-cactus uses a single reference chosen by the user as a backbone and then progressively adds complexity to the graph by aligning the other sequences.


rm -rf cactus-scratch && mkdir cactus-scratch

# Run minigraph-cactus
singularity exec -H $(pwd) docker://quay.io/comparative-genomics-toolkit/cactus:v2.6.13 \
cactus-pangenome ./js ./hprc10.seqfile --outDir ./hprc10 --outName hprc10 --reference GRCh38 CHM13 \
--filter 2 --haplo --giraffe filter --viz --odgi --chrom-vg clip filter --chrom-og --gbz clip filter full \
--gfa clip full --vcf --vcfReference GRCh38 CHM13 --logFile ./hprc10.log --workDir ./cactus-scratch \
--consCores 8 --mgMemory 128Gi


# Pangenome graph properties
# 1- Size of the graph
vg stats -lz ./hprc10/hprc10.gbz

# 2- size of the graph with telomers
vg stats -lz ./hprc10/hprc10.full.gbz


# 3- check the amount of haplotypes sequences from father and mother
vg paths -x ./hprc10/hprc10.gbz -S HG00438 -E | awk '{sum += $2} END {print sum}'
vg paths -x ./hprc10/hprc10.gbz -Q HG00438#1 -E | awk '{sum += $2} END {print sum}'
vg paths -x ./hprc10/hprc10.gbz -Q HG00438#2 -E | awk '{sum += $2} END {print sum}'

# 4- Break up the graph by component
mkdir chrom-components
vg chunk -x ./hprc10/hprc10.gbz -C -b ./chrom-components/chunk -t 32

# 5- subgraph extraction (lrc_kir region)
vg chunk -x ./hprc10.gbz -S ./hprc10.snarls -p GRCh38#0#chr19:54015634-55094318 -O gfa > ./lrc_kir.gfa

# 6- If I need to work on non-ref sample
bash -c "vg convert  ./hprc10.full.gbz -x > ./hprc10.full.xg"


#----------------------------------------------------------------------------------------------------#

# Part 3: Mapping Long Reads to the Graph
# conversion into gfa format
bash -c "vg convert ./hprc10/hprc10.gbz -f --vg-algorithm > ./hprc10/hprc10.gbz.gfa"

GraphAligner -g ./hprc10/hprc10.gbz.gfa -f sample.name.fastq.gz -a HG002.hifi.gam -x vg -t 32

# Surjecting To BAM
bash -c "vg giraffe -Z ./hprc10/hprc10.gbz -f ./hprc10/HG002.hiseqx.pcr-free.30x.R1.fastq.gz -f ./hprc10/HG002.hiseqx.pcr-free.30x.R2.fastq.gz -o bam --sample HG002 --progress --kff-name ./hg002.kff --haplotype-name ./hprc10/hprc10.hapl -R 'ID:1 LB:lib1 SM:HG002 PL:illumina PU:unit1' --ref-paths ./grch38.paths.txt > ./hprc10/hprc10.hg002.new.bam"

#-----------------------------------------------------------------------------------------------------#

# Variant Calling with DeepVariant
bash -c "vg paths -x ./hprc10/hprc10.gbz -S GRCh38 -F > ./GRCh38.fa"
samtools faidx ./GRCh38.fa

PicardCommandLine CreateSequenceDictionary R=./GRCh38.fa O=./GRCh38.dict
samtools reheader ./GRCh38.dict ./hprc10/hprc10.hg002.new.bam > ./hprc10/hprc10.hg002.new.fix.bam

samtools sort  ./hprc10/hprc10.hg002.new.bam -O BAM -o ./hprc10/hprc10.hg002.new.sort.bam --threads 8
samtools index ./hprc10/hprc10.hg002.new.sort.bam -@ 8

singularity exec -H $(pwd) docker://google/deepvariant:1.6.0 \
  /opt/deepvariant/bin/run_deepvariant \
  --model_type=WGS \
  --ref=./GRCh38.fa \
  --reads=./hprc10/hprc10.hg002.new.sort.bam\
  --output_vcf=./hprc10/hprc10.hg002.new.dv.vcf.gz \
  --output_gvcf=./hprc10/hprc10.hg002.new.dv.g.vcf.gz \
  --make_examples_extra_args="min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true" \
  --num_shards=32

#--------------------------------------------------------------------------------------------------#

# SNVstory
docker-compose build
aws s3 sync s3://igm-public-dropbox/snvstory/resource_dir/ dev/data/resource_dir/ --no-sign-request

docker-compose run ancestry \
    --path /hprc10/hprc10.hg002.new.dv.vcf.gz \
    --resource "/data/resource_dir" \
    --output-dir s3://path-to-output-directory \
    --genome-ver 38 \
    --mode WES
